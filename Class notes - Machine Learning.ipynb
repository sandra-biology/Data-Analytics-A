{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55b4369",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "- growing technology which enables computers to learn from past experiences\n",
    "- AI vs machine learning\n",
    "    - machine learning is subset of AI\n",
    "        - development of algorithms and statistical models that enable learning from past experiences\n",
    "    - definition coined in the 1950s: machine learning enables machine to automatically learn from data, improve performance from experiences and predict things without being explicitly programmed\n",
    "- traditional programming vs machine learning\n",
    "    - traditional programming: data + program -> computer -> output\n",
    "    - machine learning: data + output -> computer -> program\n",
    "- classifications of machine learning\n",
    "    - supervised learning\n",
    "    - unsupervised learning\n",
    "    - reinforcement learning\n",
    "- regression vs classification\n",
    "    - regression: uses machine learning algorithms to learn continuous mapping function\n",
    "    - classification: algorithms want to learn discrete mapping function\n",
    "- types of unsupervised learning\n",
    "    - dimensionality reduction: reduces number of dimensions from high to low while retaining critical data\n",
    "    - no labeled data\n",
    "- reinforcement learning: feedback learning method\n",
    "    - right action gets a reward\n",
    "    - wrong action gets a penalty\n",
    "- batch vs onlien learning: based on production\n",
    "    - batch (offline, then deployed): system cannot learn incrementally\n",
    "        - batches of data\n",
    "    - online learning: training happens incrementally as data arrives\n",
    "        - good option if you have limited computer resources\n",
    "- instance-based vs model-based learning\n",
    "    - instance-based: involves memorizing training data\n",
    "    - model-based: constructs models from training data\n",
    "- machine learning process: data collection -> data exploration -> data preparation -> modeling -> evaluation (circles back to modeling, iterate to find best model)\n",
    "    - 80% of the time is usually spent in data collection, data exploration, data preparation stages\n",
    "    - steps\n",
    "        - frame the problem\n",
    "        - gather data\n",
    "        - data preprocessing/cleaning\n",
    "        - model training/evaluation\n",
    "        - model deployment\n",
    "        - model testing\n",
    "        - model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae9eec",
   "metadata": {},
   "source": [
    "#### Regression analysis\n",
    "- regression: supervised learning technique which helps in finding correlation between variables\n",
    "    - mainly used for prediction\n",
    "- multicolinearity: independent variables are high correlated with each other\n",
    "- overfitting: algorithm works well with training dataset, but nto test dataset\n",
    "- underfitting: algorithm does not even work well with training dataset\n",
    "- goal with linear regression is to find best fit line where distance between measured and predicted values is minimized\n",
    "- ordinary least squares is method used for determining best fit line in linear regression\n",
    "- gradient descent\n",
    "    - iterative algorithm to train machine learning and deep learning methods\n",
    "    - helps in finding the local minimum of a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5e7045",
   "metadata": {},
   "source": [
    "#### Supervised machine learning\n",
    "- linear regression is supervised learning\n",
    "- Scikit Learn: library containing many machine learning algorithms\n",
    "    - algorithms imported, fitted\n",
    "    - users can swap algorithms in and out and test various approaches\n",
    "- regression metrics\n",
    "    - mean absolute error: calculates absolute difference between actual and predicted\n",
    "        - same unit as output variable\n",
    "        - most robust to outliers\n",
    "    - mean squared error: finds squared difference\n",
    "        - graph is differiable\n",
    "        - unit is squared unit of output variable\n",
    "        - penalizes outliers the most\n",
    "    - root mean squared error: square root of mean squared error\n",
    "        - have to use NumPy square root function on mean squared error\n",
    "- often for linear regression it's good to calculate residuals, not just metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8853ba",
   "metadata": {},
   "source": [
    "#### Regression and correlation\n",
    "- mupltiple linear regression: extension of simple linear regression as it takes more than one predictor variable to predict the response variable\n",
    "- polynomial regression\n",
    "    - extension of linear regression\n",
    "    - models relationship between independent variable and dependent variable as nth degree polynomial\n",
    "- correlation: need to convert categorical columns to numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246414ae",
   "metadata": {},
   "source": [
    "#### Bias-variance trade-off\n",
    "- bias: prediction error introduced in the model due to oversimplifying the machine learning algorithms\n",
    "- variance: occurs when the model performs well with training but not test dataset\n",
    "- bias is oversimplified, variance is overcomplicated\n",
    "- classification algorithm: supervised learning, identifies category of new observations into classes or groups on the basis of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c4d4c",
   "metadata": {},
   "source": [
    "#### Logistic regression\n",
    "- classification algorithm\n",
    "- predicts output of a categorical depedent variable, gives probablistic values between 0 and 1\n",
    "- curve indicates the likelihood of something\n",
    "- uses continuous and discrete datasets\n",
    "- using the sigmoid function we can convert continuous data into categorical/discrete data\n",
    "- validation dataset used to\n",
    "    - evaluate model during training\n",
    "    - tune model hyperparameters\n",
    "    - pick best version of the model\n",
    "- imputation: process of filling in missing values\n",
    "- need good amount of data for the train dataset\n",
    "- continuous variables need to be scaled if they're on different ranges\n",
    "- categorical variables need to be encoded if their values are not numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d4c164",
   "metadata": {},
   "source": [
    "#### K-nearest neighbors\n",
    "- similarity between new case and available cases\n",
    "- classifies new case/data point based on similarity\n",
    "- advantages\n",
    "    - simple to implement\n",
    "    - can be more effective if training set is large\n",
    "- disadvantages\n",
    "    - always need to determine k\n",
    "    - high computaiton cost because distance needs to be computed between data points for all training samples\n",
    "- hyperparameters: parameters whose values control the learning process and determine values of model parameters\n",
    "    - k in k-nearest neighbors\n",
    "- grid search: a way of training and validating a model on every possible combination of multiple hyperparameter options"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
